{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":4,"colab":{"name":"Copy of test_ddpg_colab.ipynb","provenance":[{"file_id":"https://github.com/naufalhisyam/rocket-lander/blob/paper-training/test_ddpg_colab.ipynb","timestamp":1629420370802}],"collapsed_sections":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Zc-W44uPA9M-"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"98uUUZk3A9NE"},"source":["!apt install python-opengl\n","!apt install ffmpeg\n","!apt install xvfb\n","\n","!pip install cvxpy\n","!pip install box2d-py\n","!pip uninstall pyglet -y\n","!pip uninstall gym -y\n","!pip install pyglet==1.3.2\n","!pip install gym==0.9.4\n","!pip install pyvirtualdisplay"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eHe97WWFA9NG"},"source":["!git clone -b paper-training https://github.com/naufalhisyam/rocket-lander.git\n","%cd /content/rocket-lander\n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W6oz1BXxA9NI"},"source":["# Virtual display\n","from pyvirtualdisplay import Display\n","from pyvirtualdisplay import Display\n","\n","virtual_display = Display(visible=0, size=(1000, 800))\n","virtual_display.start()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bsodrhCaA9NJ"},"source":["%tensorflow_version 1.x\n","import os\n","import numpy as np\n","from numpy.core.numeric import False_\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from control_and_ai.DDPG.ddpg import DDPG\n","from control_and_ai.DDPG.utils import Utils\n","from control_and_ai.DDPG.exploration import OUPolicy\n","\n","from constants import *\n","from constants import DEGTORAD\n","from environments.rocketlander_test import RocketLander, get_state_sample\n","\n","action_bounds = [1, 1, 15*DEGTORAD]\n","\n","eps = []\n","eps.append(OUPolicy(0, 0.2, 0.4))\n","eps.append(OUPolicy(0, 0.2, 0.4))\n","eps.append(OUPolicy(0, 0.2, 0.4))\n","\n","simulation_settings = {'Side Engines': True,\n","                       'Clouds': True,\n","                       'Vectorized Nozzle': True,\n","                       'Graph': False,\n","                       'Render': False,\n","                       'Starting Y-Pos Constant': 1,\n","                       'Initial Force': 'random',\n","                       'Rows': 1,\n","                       'Columns': 2,\n","                       'Episodes': 500,\n","                       'Initial Coordinates': (W/2 - 10, 25.2, 0, False)} # xx, yy, randomness_degree, normalized\n","\n","env = RocketLander(simulation_settings)\n","#env = wrappers.Monitor(env, './rocket_videos', force=True)\n","\n","#Set both line below to False if you want to contniue training from a saved checkpoint\n","RETRAIN = False#Restore weights if False\n","TEST = True #Test the model\n","\n","NUM_EPISODES = 1\n","SAVE_TO_EXCEL = True #Export states & actions logs as .xlsx\n","\n","NAME = \"Tanpa Angin_1000 eps_x0_-10\" #Model name\n","\n","SIMULATE_WIND = True\n","x_force = 0 # x-axis wind force in Newton. x_force awal = 2000\n","y_force = 0 # y-axis wind force in Newton. y_force awal = 2000\n","\n","model_dir = '/content/gdrive/MyDrive/colab_model/rocket/DDPG/' + NAME\n","\n","agent = DDPG(\n","    action_bounds,\n","    eps,\n","    env.observation_space.shape[0], #for first model\n","    actor_learning_rate=0.001,\n","    critic_learning_rate=0.01,\n","    retrain=RETRAIN,\n","    log_dir=\"./logs\",\n","    model_dir=model_dir,\n","    batch_size=100,\n","    gamma=0.99)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DFyuSou1A9NM"},"source":["def test(env, agent, x_force, y_force):\n","    obs_size = env.observation_space.shape[0]\n","\n","    util = Utils()\n","    state_samples = get_state_sample(samples=5000, normal_state=True)\n","    util.create_normalizer(state_sample=state_samples)\n","    xpos, ypos, xvel, yvel, lander_angle, angular_vel, rem_fuel, lander_mass, xpos_rocket, ypos_rocket, xpos_landingPad, ypos_landingPad = ([] for _ in range(12))\n","    fE, fS, pSi = ([] for _ in range(3))\n","    if SIMULATE_WIND:\n","        wind_x, wind_y = ([] for _ in range(2))\n","    \n","    for episode in range(1, NUM_EPISODES + 1):\n","        old_state = None\n","        done = False\n","        total_reward = 0\n","\n","        state = env.reset()\n","        state = util.normalize(state)\n","        max_steps = 500\n","\n","        left_or_right_barge_movement = np.random.randint(0, 2)\n","\n","        for t in range(max_steps): # env.spec.max_episode_steps\n","            old_state = state\n","            # infer an action\n","            action = agent.get_action(np.reshape(state, (1, obs_size)), not TEST)\n","            \n","            current_state = env.get_state_with_barge_and_landing_coordinates(untransformed_state=True)\n","                \n","            xpos.append(current_state[0]-current_state[12]) #xpos_rocket - xpos_landingPad\n","            ypos.append(current_state[1]-current_state[13]) #ypos_rocket - ypos_landingPad\n","            xvel.append(current_state[2]) #xdot\n","            yvel.append(current_state[3]) #ydot\n","            lander_angle.append(current_state[4]) #theta\n","            angular_vel.append(current_state[5]) #theta_dot\n","            rem_fuel.append(current_state[6]) #initial fuel = 0.2 * initial_mass\n","            lander_mass.append(current_state[7]) #initial_mass = 25.222\n","            xpos_rocket.append(current_state[0]) # xpos_rocket\n","            ypos_rocket.append(current_state[1]) # ypos_rocket\n","            xpos_landingPad.append(current_state[12]) # xpos_landingPad\n","            ypos_landingPad.append(current_state[13]) # ypos_landingPad\n","                \n","            fE.append(action[0][0])\n","            fS.append(action[0][1])\n","            pSi.append(action[0][2])\n","\n","            # take it\n","            state, reward, done, _ = env.step(action[0])\n","            state = util.normalize(state)\n","            total_reward += reward\n","\n","            if SIMULATE_WIND:\n","                if state[LEFT_GROUND_CONTACT] == 0 and state[RIGHT_GROUND_CONTACT] == 0:\n","                    env.apply_random_x_disturbance(epsilon=0, left_or_right=left_or_right_barge_movement, x_force=x_force) # epsilon awal = 0.005\n","                    env.apply_random_y_disturbance(epsilon=0, y_force=y_force) # epsilon awal = 0.005\n","                    if SAVE_TO_EXCEL:\n","                        winds = env.get_winds_value()\n","                        wind_x.append(winds[0])\n","                        wind_y.append(winds[1])\n","            \n","\n","            if done:\n","                break\n","\n","        agent.log_data(total_reward, episode)\n","\n","        print(\"Episode:\\t{0}\\tReward:\\t{1}\".format(episode, total_reward))\n","    \n","    if SAVE_TO_EXCEL:\n","        os.makedirs(\"excel_logs/states-acts/\", exist_ok=True)\n","        state_data=pd.DataFrame(list(zip(xpos,ypos,xvel,yvel,lander_angle,angular_vel,rem_fuel,lander_mass,xpos_rocket,ypos_rocket,xpos_landingPad,ypos_landingPad)),\\\n","            columns=['x_pos','y_pos','x_vel','y_vel','lateral_angle','angular_velocity','remaining_fuel','lander_mass','xpos_rocket','ypos_rocket','xpos_landingPad','ypos_landingPad'])\n","        action_data=pd.DataFrame(list(zip(fE,fS,pSi)),columns=['Fe','Fs','Psi'])\n","        if SIMULATE_WIND:\n","            wind_dat= pd.DataFrame(list(zip(wind_x, wind_y)),columns=['x_wind force', 'y_wind force'])\n","                \n","        with pd.ExcelWriter(f\"/content/rocket-lander/excel_logs/states-acts/DDPG_{NAME}_{total_reward}.xlsx\") as writer:\n","            state_data.to_excel(writer, sheet_name=\"state\")\n","            action_data.to_excel(writer, sheet_name=\"action\")\n","            if SIMULATE_WIND:\n","                wind_dat.to_excel(writer, sheet_name=\"winds\")    \n","        !cp -a \"/content/rocket-lander/excel_logs/states-acts/.\" \"{model_dir}\"\n","        print(\"Logs saved\")\n","    \n","    env.close()\n","    \n","    fig, ax = plt.subplots()\n","    ax.set_ylim(0,21)\n","    ax.set_xlim(-10,10)\n","    ax.plot(xpos, ypos, color='maroon')\n","    ax.axvline(x=0, c='gray', linewidth=0.7)\n","    ax.set_title('Rocket landing trajectory')\n","    ax.set_xlabel('x position (m)')\n","    ax.set_ylabel('y position (m)')\n","    ax.grid()\n","    print(f\"X miss distance : {xpos[-1]}\\nY miss distance : {ypos[-1]}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V0QUW3lsA9NQ"},"source":["test(env, agent, x_force, y_force)"],"execution_count":null,"outputs":[]}]}